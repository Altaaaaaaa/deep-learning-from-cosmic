{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 신경망\n",
    "CNN은 이미지 인식과 음성 인식 등 다양한 곳에서 사용된다. 특히 이미지 인식분야에서 딥러닝을 활용한 기법은 거의 다 CNN을 기초로 한다.\n",
    "CNN의 네트워크 구조\n",
    "합성곱 계층\n",
    "풀링 계층\n",
    "지금 까지 본 신경망은 인접하는 계층의 모든 뉴런과 결합되어 있다. 이를 완전연결이라고 하며완전히 연결된 계층을 Affine계층이라 부른다.\n",
    "Affine계층뒤에 활성화 함수를 갖는다.\n",
    "CNN은 Conv-ReLU-(Pooling)흐름으로 연결된다. \n",
    "CNN에서는 패딩, 스트라이드라는 용어가 등장한다. 각 계층 사이에는 3차원 데이터와 같이 입체적인 데이터가 흐른다는 점에서 완전연결 신경망과 다르다.\n",
    "완전연결 계층의 문제점\n",
    "완전연결 계층은 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있습니다.\n",
    "이러한 문제점은 데이터의 형상이 무시된다는 것입니다.\n",
    "이미지의 경우 통상 세로 가로 채널로 구성된 3차원 데이터입니다. 그러나 완전연결 계층에 입력할 때는 3차원 데이터를 평평한 1차원 데이터로 평탄화해줘야합니다.\n",
    "이미지는 3차원 형상이기때문에 공간정보가 담겨있다.RGB나 픽셀등 본질적인 패턴이 의미가 있는것이 숨겨져있을 수 있다. 이러한 정보를 무시함\n",
    "\n",
    "합성공 계층은 이러한 형상을 유지할 수 있다.\n",
    "CNN에서는 합성곱계층의 입출력 데이터를 특징 맵이라고 한다.\n",
    "입력데이터를 입력 특징 맵, 출력 데이터를 출력 특징 맵이라한다.\n",
    "합성곱 연산\n",
    "이미지 처리에서 말하는 필터 연산에 해당한다.\n",
    "합성곱연산에는 입력 데이터와 필터가 적용되는데 이 필터를 커널이라고 한다.\n",
    "합성곱 연산은 필터의 윈도우를 일정 간격으로 이동해가며 입력데이터에 적용합니다.\n",
    "여기서 윈도우는 3*3부분을 가리킨다.\n",
    "그 후 입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구합니다.(단일 곱셈-누산) 그 결과를 출력의 해당장소에 저장합니다.\n",
    "CNN에서 필터의 매개변수가 가중치에 해당한다. CNN에도 편향이 존재한다.\n",
    "출력값에+편향을 하는 것이다.\n",
    "\n",
    "패딩\n",
    "합성곱 연산을 수행하기 전에 입력 데이터 주변을 특정 값으로 채우기도 한다. 이를 패딩이라 한다.\n",
    "\n",
    "스트라이드\n",
    "필터를 적용하는 위치의 간격\n",
    "스트라이드가 2라면 3*3을 한 후 2칸 옆으로 이동\n",
    "OH=(H+2P-FH)/S+1\n",
    "OW=(W+2P-FW)/S+1\n",
    "결과값이 나누어 떨어져야함\n",
    "\n",
    "3차원 데이터의 합성곱 연산\n",
    "입력데이터의 채널수와 필터의 채널 수가 같아야한다.\n",
    "\n",
    "필터의 크기는 상관없음\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.3 풀링 계층\n",
    "세로 가로 방향의 공간을 줄이는 연산이다.\n",
    "2*2 최대풀링을 스트라이드 2로 처리하는 순서이다.\n",
    "최대 풀링은 최댓값을 구하는 연산으로 2*2는 대상영역의 크기를 뜻한다. \n",
    "만약 윈도우 4*4면 스트라이드는 4로 설정한다.\n",
    "풀링 계층의 특징\n",
    "1. 학습해야할 매개변수가 없다.\n",
    "2. 채널수가 변하지 않는다.//풀링 연산은 입력 데이터의 채널 수 그대로 출력 데이터로 내보낸다.\n",
    "3.입력의 변화에 영향을 적게 받는다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4차원 배열\n",
    "CNN에서 계층 사이를 흐르는 데이터는 4차원이다. 데이터의 형상이 (10,1,28,28)이면 높이 28 너비28 채널 1개 데이터가 10개이다.\n",
    "\n",
    "im2col데이터 전개\n",
    "입력데이터를 필터링 하기 좋게 전개하는 함수이다. \n",
    "다차원을 2차원으로 바꿔줌\n",
    "스트라이드를 크게잡아 적용영역이 겹치지 않도록 하기도 하지만 겹치면 im2col로 전개한 후 원소의 수가 원래 블록의 원소 수보다 많아진다. 그래서 im2col을 사용해 구현하면 메모리를 더 많이 소비하는 단점이 있다.\n",
    "im2col로 입력데이터를 전개한 다음 합성곱 계층의 필터를 1열로 전개하고 두 행렬의 내적을 계산합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.random.rand(10, 1, 28, 28)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def smooth_curve(x):\n",
    "    \"\"\"손실 함수의 그래프를 매끄럽게 하기 위해 사용\n",
    "    \n",
    "    참고：http://glowingpython.blogspot.jp/2012/02/convolution-with-numpy.html\n",
    "    \"\"\"\n",
    "    window_len = 11\n",
    "    s = np.r_[x[window_len-1:0:-1], x, x[-1:-window_len:-1]]\n",
    "    w = np.kaiser(window_len, 2)\n",
    "    y = np.convolve(w/w.sum(), s, mode='valid')\n",
    "    return y[5:len(y)-5]\n",
    "\n",
    "\n",
    "def shuffle_dataset(x, t):\n",
    "    \"\"\"데이터셋을 뒤섞는다.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : 훈련 데이터\n",
    "    t : 정답 레이블\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x, t : 뒤섞은 훈련 데이터와 정답 레이블\n",
    "    \"\"\"\n",
    "    permutation = np.random.permutation(x.shape[0])\n",
    "    x = x[permutation,:] if x.ndim == 2 else x[permutation,:,:,:]\n",
    "    t = t[permutation]\n",
    "\n",
    "    return x, t\n",
    "\n",
    "def conv_output_size(input_size, filter_size, stride=1, pad=0):\n",
    "    return (input_size + 2*pad - filter_size) / stride + 1\n",
    "\n",
    "\n",
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"다수의 이미지를 입력받아 2차원 배열로 변환한다(평탄화).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_data : 4차원 배열 형태의 입력 데이터(이미지 수, 채널 수, 높이, 너비)\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    col : 2차원 배열\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col\n",
    "\n",
    "\n",
    "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
    "    \"\"\"(im2col과 반대) 2차원 배열을 입력받아 다수의 이미지 묶음으로 변환한다.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    col : 2차원 배열(입력 데이터)\n",
    "    input_shape : 원래 이미지 데이터의 형상（예：(10, 1, 28, 28)）\n",
    "    filter_h : 필터의 높이\n",
    "    filter_w : 필터의 너비\n",
    "    stride : 스트라이드\n",
    "    pad : 패딩\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    img : 변환된 이미지들\n",
    "    \"\"\"\n",
    "    N, C, H, W = input_shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
    "\n",
    "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
    "\n",
    "    return img[:, :, pad:H + pad, pad:W + pad]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "\n",
    "x1=np.random.rand(1,3,7,7)\n",
    "col1=im2col(x1,5,5,stride=1,pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2=np.random.rand(10,3,7,7)\n",
    "col2=im2col(x2,5,5,stride=1,pad=0)\n",
    "print(col2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self,W,b,stride=1,pad=0):\n",
    "        self.W=W;\n",
    "        self.b=b;\n",
    "        self.stride=stride\n",
    "        self.pad=pad\n",
    "        \n",
    "    def forward(self,x):\n",
    "        FN,C,FH,FW=self.W.shape\n",
    "        N,C,W,H=x.shape\n",
    "        out_h=int(1+(H+2*self.pad-FH)/self.stride)\n",
    "        out_w=int(1+(W+2*self.pad=FW)/self.stride)\n",
    "        \n",
    "        col=im2col(x,FH,FW,self.stride,self.pad)\n",
    "        col_W=self.W.reshape(FN,-1).T\n",
    "        out=np.dot(col,col_W)+self.b\n",
    "        \n",
    "        out=out.reshape(N,out_h,out_w,-1).transpose(0,3,1,2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transpose함수-> 출력데이터를 적절한 형상으로 바꿔준다.\n",
    "다차원 배열의 축 순서를 바꿔준다.\n",
    "풀링 계층 구현\n",
    "1. 입력 데이터를 전개한다.\n",
    "2. 행별 최댓값을 구한다.\n",
    "3. 적절한 모양으로 성형한다.\n",
    "\n",
    "CNN구현하기\n",
    "합성곱 계층의 하이퍼파라미터는 딕셔너리 형태로 주어진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN의 원조 LeNet, AlexNet\n",
    "LeNet->손글씨 인식 네트워크\n",
    "합성곱계층과 풀링계층을 반복하고 마지막으로 완전연결계층을 거쳐결과출력\n",
    "LeNet은 시그모이드 함수를 사용함\n",
    "AlexNet은 활성화함수 ReLu를 사용하고LRN이라는 국소적정규화를 실시하는 계층을 이용하고 드롭아웃을 사용한다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b46e0f8da782ee4e5836de201b49d269b788967913c4102a2cdd310d10725f3c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
