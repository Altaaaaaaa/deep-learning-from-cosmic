{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter8 딥러닝  \n",
    "딥러닝은 층을 깊게 한 심층 신경망  \n",
    "\n",
    "8.1.2 정확도를 높이려면  \n",
    "데이터 확장(data augmentation): 입력 이미지(훈련 이미지)를 알고리즘을 동원해 '인위적'으로 확장한다.  \n",
    "입력 이미지를 회전하거나 세로로 이동하는 등 미세한 변화를 주어 이미지의 개수를 늘리는 것 -> 데이터가 몇 개 없을 때 특히 효과적  \n",
    "데이터 확장은 변형 외에도 이미지 일부를 잘라내는 crop이나 좌우를 뒤집는 flip 등이 있다.  \n",
    "일반적인 이미지에는 밝기 등의 외형 변화나 확대, 축소 등의 스케일 변화도 효과적이다.  \n",
    "\n",
    "8.1.3 깊게 하는 이유  \n",
    "층을 깊게 할 때의 이점  \n",
    "1. 신경망의 매개변수 수가 줄어든다.  \n",
    "-> 층을 깊게 한 신경망은 깊지 않은 경우보다 적은 매개변수로 같은(혹은 그 이상) 수준의 표현력을 달성할 수 있다.  \n",
    "5*5 합성곱 계층을 5x5필터 1번과 3x3 필터로 2번 반복한 출력 데이터의 크기는 같지만 매개변수 수는 차이가 난다. 전자는 25 후자는 18  \n",
    "\n",
    "작은 필터를 겹쳐 신경망을 깊게 할 때의 장점은 매개변수 수를 줄여 넓은 수용 영역(receptive field)을 소화할 수 있다.  \n",
    "(수용 영역은 뉴런에 변화를 일으키는 국소적인 공간 영역)  \n",
    "\n",
    "2. 학습의 효율성  \n",
    "-> 층을 깊게 함으로써 학습 데이터의 양을 줄여 학습을 고속으로 수행할 수 있다.\n",
    "학습해야할 문제를 계층적으로 분해할 수 있어, 각 층이 학습해야 할 문제를 더 단순한 문제로 대체할 수 있다.  \n",
    "정보를 계층적으로 전달할 수 있다.  \n",
    "즉, 층을 깊이 함으로써 각 층이 학습해야 할 문제를 '풀기 쉬운 단순한 문제'로 분해할 수 있어 효율적으로 학습 가능하다.  \n",
    "\n",
    "8.2 딥러닝의 초기 역사  \n",
    "딥러닝이 지금처럼 큰 주목을 받게 된 계기는 이미지 인식 기술을 겨루는 장인 ILSVRC(ImageNet Large Scale Visual Recongnition Challenge)의 2012년 대회다.  \n",
    "\n",
    "8.2.1 이미지넷  \n",
    "이미지넷(ImageNet): 100만 장이 넘는 이미지를 담고 있는 데이터셋\n",
    "ILSVRC 대회에서는 시험 항목이 몇 가지 있는데, 그중 하나가 분류(classfication)이다.  \n",
    "\n",
    "8.2.2 VGG  \n",
    "VGG: 합성곱 계층과 풀링 계층으로 구성되는 '기본적'인 CNN이다.  \n",
    "비중 있는 층(합성곱 계층, 완전연결 계층)을 모두 16층(혹은 19층)으로 심화한게 특징 (층의 깊이에 따라서 'VGG16'과 'VGG19'로 구분)  \n",
    "VGG에서 주목할 점은 3x3의 작은 필터를 사용한 합성곱 계층을 연속으로 거친다는 것  \n",
    "합성곱 계층을 2~4회 연속으로 풀링 계층을 두어 크기를 절반으로 줄이는 처리를 반복  \n",
    "마지막에는 완전연결 계층을 통과시켜 결과를 출력  \n",
    "\n",
    "8.2.3 GoogLeNet  \n",
    "GoogLeNet은 세로 방향 깊이뿐 아니라 가로 방향도 깊다는 점이 특징  \n",
    "GoogLeNet에는 가로 방향에 폭이 있다. -> 인셉션 구조  \n",
    "인셉션 구조는 크기가 다른 필터(와 풀링)를 여러 개 적용하여 그 결과를 결합  \n",
    "인셉션 구조를 하나의 빌딩 블록(구성요소)으로 사용하는 것이 GoogLeNet의 특징  \n",
    "GoogLeNet에서는 1x1의 합성곱 연산은 채널 쪽으로 크기를 줄이는 것으로 매개변수 제거와 고속 처리에 기여한다.  \n",
    "\n",
    "8.2.4 ResNet  \n",
    "ResNet(Residual Network)은 마이크로소프트의 팀이 개발한 네트워크다.  \n",
    "딥러닝의 학습에서는 층이 지나치게 깊으면 학습이 잘 되지 않고, 오히려 성능이 떨어지는 경우도 많다.  \n",
    "-> ResNet에서는 그런 문제를 해결하기 위해 스킵 연결(skip to connection) 도입   \n",
    "-> 층의 깊이에 비례해 성능을 향상시킬 수 있게 한 핵심(층을 깊게 하는 데는 여전히 한계 존재)  \n",
    "\n",
    "스킵 연결: 입력 데이터를 합성곱 계층을 건너뛰어 출력에 바로 더하는 구조  \n",
    "스킵 연결은 층이 깊어져도 학습을 효율적으로 할 수 있도록 한다. -> 역전파 때 스킵 연결이 신호 감쇠를 막아주기 때문  \n",
    "\n",
    "스킵 연결은 입력 데이터를 '그대로' 흘리는 것으로, 역전파 때도 상류의 기울기를 그대로 하류로 보낸다.  \n",
    "여기에서의 핵심은 상류의 기울기에 아무런 수정도 가하지 않고 '그대로' 흘린다는 것이다.  \n",
    "스킵 연결로 기울기가 작아지거나 지나치게 커질 걱정 없이 앞 층에 '의미 있는 기울기'가 전해지리라 기대할 수 있다.  \n",
    "층을 깊게 할수록 기울기가 작아지는 소실 문제를 스킵 연결이 줄여준다.  \n",
    "\n",
    "ResNet은 VGG 신경망을 기반으로 스킵 연결을 도입하여 층을 깊게 했다.  \n",
    "ResNet은 합성곱 계층을 2개 층마다 건너뛰면서 층을 깊게 한다.  \n",
    "\n",
    "전이 학습(transfer learning): 학습된 가중치(혹은 그 일부)를 다른 신경망에 복사한 다음, 그상태로 재학습 수행  \n",
    "전이 학습은 보유한 데이터셋이 적을 때 특히 유용한 방법  \n",
    "\n",
    "8.3 딥러닝 고속화  \n",
    "최근 프레임워크에서 복수의 GPU와 여러 기기로 분산 수행하기 시작  \n",
    "\n",
    "8.3.1 풀어야 할 숙제  \n",
    "딥러닝 중 AlexNet에서는 오랜 시간을 합성곱 계층에 소요한다.    \n",
    "\n",
    "딥러닝 고속화는 대량의 '단일 곱셈-누산'을 어떻게 고속으로 효율적으로 계산하느냐는 것이다.  \n",
    "\n",
    "8.3.2 GPU를 활용한 고속화  \n",
    "GPU 컴퓨팅: GPU로 범용 수치 연산을 수행하는 것  \n",
    "목적: GPU는 병렬 수치 연산을 고속으로 처리할 수 있으니, 그 압도적인 힘을 다양한 용도로 활용하자는 것  \n",
    "\n",
    "대량 병렬 연산은 GPU의 장점(반대로 CPU는 연속적인 복잡한 계산이 장점)  \n",
    "\n",
    "GPU는 주로 엔비디아, AMD 두 회사가 제공한다.  \n",
    "딥러닝과 더 '친한' 쪽은 아직 엔비디아다.  \n",
    "엔비디아의 GPU 컴퓨팅용 통합 개발 환경인 CUDA를 사용하기 때문  \n",
    "cuDNN은 CUDA 위에서 동작하는 라이브러리로, 딥러닝에 최적화도니 함수 등이 구현되어 있다.  \n",
    "\n",
    "8.3.3. 분산 학습  \n",
    "1회 학습에 걸리는 시간을 단축하기 위해 딥러닝 학습을 수평확장(scale out)하자는 아이디어(분산 학습)가 중요해진다.  \n",
    "구글의 텐서플로와 마이크로소프트의 CNTK(Computational Network Toolkit)는 분산 학습에 역점을 두고 개발하고 있다.  \n",
    "GPU 수가 많을수록 학습이 빨라진다.  \n",
    "\n",
    "8.3.4 연산 정밀도와 비트 줄이기  \n",
    "계산 능력 외에도 메모리 용량과 버스 대역폭 등이 딥러닝 고속화에 병목이 될 수 있다.  \n",
    "메모리 용량 면에서는 대량의 가중치 매개변수와 중간 데이터를 메모리에 저장해야 한다는 것을 생각해야 한다.\n",
    "버스 대역폭 면에서는 GPU(혹은 CPU)의 버스를 흐르는 데이터가 많아져 한계를 넘어서면 병목이 된다.  \n",
    "-> 네트워크로 주고받는 데이터의 비트 수는 최소로 만드는 것이 바람직  \n",
    "\n",
    "많은 비트를 사용할수록 계산 오차는 줄어들지만, 그만큼 계싼에 드는 비용과 메모리 사용량이 늘고 버스 대역폭에 부담을 준다.  \n",
    "딥러닝은 높은 수치 정밀도(수치를 몇 비트로 표현하느냐)를 요구하지 않는다. -> 신경망의 중요한 성질로, 신경망의 견고성에 따른 특성  \n",
    "\n",
    "컴퓨터에서 실수를 표현하는 방식으로 32비트 단정밀도(simple-precision), 64비트 배정밀도(double-precision) 부동소수점 등의 포맷이 있다.  \n",
    "딥러닝은 16비트 반정밀도(half-precision)만 사용해도 학습에 문제가 없다고 알려져 있다.  \n",
    "\n",
    "파이썬에서는 일반적으로 64비트 배정밀도 부동소수점 수를 사용한다.  \n",
    "넘파이는 16비트 반정밀도 부동소수점도 지원한다. 이를 사용해도 정확도가 떨어지지 않는 것을 쉽게 확인 가능(스토리지로서 16비트라는 틀이 있을 뿐, 연산 자체는 16비트로 수행하지 않는다.)  \n",
    "\n",
    "최근에는 가중치와 중간 데이터를 1비트로 표현하는 'Binarized Neural Networks'라는 방법 등장  \n",
    "\n",
    "8.4.1 사물 검출  \n",
    "사물의 위치와 종류(클래스)를 알아내는 기술    \n",
    "사물 검출에서는 이미지 어딘가에 있을 사물의 위치까지 알아내야해서 사물 인식보다 어려운 문제다. 또, 한 이미지에 여러 사물이 존재할 수도 있다.  \n",
    "CNN 중 R-CNN(Regions with Convolutional Neural Network)가 유명하다.  \n",
    "최근에는 이 후보 영역 추출까지 CNN으로 처리하는 Faster R-CNN 기법도 등장  \n",
    "\n",
    "8.4.2 분할  \n",
    "분할(segmentation)이란 이미지를 픽셀 수준에서 분류하는 문제  \n",
    "픽셀 단위로 객체마다 채색된 지도(supervised) 데이터를 사용해 학습  \n",
    "추론할 때 입력 이미지의 모든 픽셀을 분류  \n",
    "\n",
    "신경망을 이용해 분할하는 가장 단순한 방법은 모든 픽셀 각각을 추론하는 것  \n",
    "예를 들어, 어떤 직사각형 영역의 중심 픽셀의 클래스를 분류하는 신경망을 만들어서, 모든 픽셀을 대상으로 하나씩 추론 작업을 실행한다.\n",
    "이런 식으로는 픽셀의 수만큼 forward 처리를 해야 하여 긴 시간이 걸리게 된다.(합성곱 연산에서 많은 영역을 쓸데없이 다시 계산하는 것이 문제가 된다.)  \n",
    "낭비를 줄여주는 기법으로 FCN(Fully Convolutional Network)이 고안되었다. -> 단 한 번의 forward 처리로 모든 픽셀의 클래스를 분류해주는 놀라운 기법  \n",
    "\n",
    "Fully Convolutional Network를 직역하면 '합성곱 계층만으로 구성된 네트워크'가 된다.  \n",
    "FCN은 완전연결 계층을 '같은 기능을 하는 합성곱 계층'으로 바꾼다.  \n",
    "FCN에서는 공간 볼륨을 유지한 채 마지막 출력까지 처리할 수 있다.  \n",
    "마지막에 공간 크기를 확대하는 처리를 도입했다는 것도 특징이다.  \n",
    "FCN의 마지막에 수행하는 확대하는 이중 선형 보간(bilinear interplation)에 의한 선형 확대다.  \n",
    "FCN에서는 이 선형 확대를 역합성곱(deconvolution)연산으로 구현해내고 있다.  \n",
    "\n",
    "8.4.3 사진 캡션 생성  \n",
    "딥러닝으로 사진 캡션을 생성하는 방법으로는 NIC(Neural Image Caption) 모델이 대표적  \n",
    "NIC는 심층 CNN과 자연어를 다루는 순환 신경망(Recurrent Neural Network, RNN)으로 구성된다.  \n",
    "RNN은 순환적 관계를 갖는 신경망으로 자연어나 시계열 데이터 등의 연속된 데이터를 다룰 때 많이 활용  \n",
    "NIC는 CNN으로 사진에서 특징을 추출하고, 그 특징을 RNN에 넘긴다. RNN은 CNN이 추출한 특징을 초깃값으로 해서 텍스트를 '순환적'으로 생성  \n",
    "NIC는 2개의 신경망(CNN과 RNN)을 조합한 간단한 구성  \n",
    "사진이나 자연어와 같은 여러 종류의 정보를 조합하고 처리하는 것을 멀티모달 처리(multimodal processiong)라고 한다.  \n",
    "\n",
    "8.5.1 이미지 스타일(화풍) 변환  \n",
    "네트워크의 중간 데이터가 콘텐츠 이미지의 중간 데이터와 비슷해지도록 학습  \n",
    "입력 이미지를 콘텐츠 이미지의 형태를 흉내 낼 수 있습니다.  \n",
    "스타일 이미지의 화풍을 흡수하기 위해 '스타일 행렬'이라는 개념을 도입  \n",
    "스타일 행렬의 오차를 줄이도록 학습하여 입력 이미지를 해당 화풍과 비슷하게 만든다.  \n",
    "\n",
    "8.5.2 이미지 생성  \n",
    "먼저 대량의 이미지를 사용하여 학습한다. 학습이 끝난 후에 아무런 입력 없이도 그림을 그려낸다.  \n",
    "DCGAN(Deep Convolutional Generative Adversarial Network)기법이 있다.\n",
    "DCGAN은 이미지를 생성하는 과정을 모델화한다.  모델을 대량의 이미지를 사용해 학습하고, 학습이 끝나면 그 모델을 이용하여 새로운 그림을 생성한다.  \n",
    "DCGAN도 딥러닝을 사용한다. DCGAN 기술의 핵심은 생성자(Generator)와 식별자(Discriminator)로 불리는 2개의 신경망을 이용한다는 점이다.  \n",
    "생성자가 진짜와 똑같은 이미지를 생성하고 식별자는 그것이 진짜인지(생성자가 생성한 이미지인지, 실제로 촬영된 이미지인지)를 판정한다.  \n",
    "둘을 겨루도록 학습시켜 생성자는 더 정교한 가짜 이미지 생성 기술을 학습하고 식별자는 더 정확하게 간파할 수 있는 감정사로 성장한다.  \n",
    "둘의 능력을 부지런히 갈고닦게 하는 것이 GAN(Generative Adversarial Network) 기술의 재밌는 점이다.  \n",
    "\n",
    "자율 학습(unsupervised learning): 지도용 데이터는 주어지지 않고, 단지 대량의 이미지(이미지의 집합)만 주어지면 스스로 학습하는 학습  \n",
    "\n",
    "8.5.3 자율 주행  \n",
    "SegNet이라는 CNN 기반 신경망은 주변 환경을 정확하게 인식한다.  \n",
    "입력 이미지를 분할(픽셀 수준에서 판정)하고 있다.  \n",
    "\n",
    "8.5.4 Deep Q-Network(강화학습)  \n",
    "강화학습(enforcement learning): 시행착오 과정에서 스스로 학습하는 학습  \n",
    "\n",
    "에이전트라는 것이 환경에 맞게 행동을 선택하고, 그 행동에 의해 환경이 변한다. 환경이 변화하면 에이전트는 어떠한 보상을 얻는다.  \n",
    "강화학습의 목적은 더 나은 보상을 받는 쪽으로 에이전트의 행동 지침을 바로잡는 것이다.  \n",
    "주의점은 보상은 정해진 것이 아니라 '예상 보상'이라는 점이다.  \n",
    "\n",
    "딥러닝을 사용한 강화학습 중 Deep Q-Network(DQN) 존재  \n",
    "Q학습이라는 강화학습 알고리즘을 기초로 한다.  \n",
    "Q학습에서는 최적 행동 가치 함수로 최적인 행동을 정한다.  \n",
    "이 함수를 딥러닝(CNN)으로 비슷하게 흉내 내어 사용하는 것이 DQN이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
